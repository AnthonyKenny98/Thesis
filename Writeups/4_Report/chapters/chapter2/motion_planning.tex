% @Author: AnthonyKenny98
% @Date:   2020-04-04 10:01:40
% @Last Modified by:   AnthonyKenny98
% @Last Modified time: 2020-04-06 15:18:44

A funny paradox in computer science is the fact that it is relatively easy to teach a computer to perform tasks that humans find very complicated, but extremely difficult to program one to execute functions that humans master during infancy. Consider, it was as early as 1949 that Claude Shannon presented his paper \textit{Programming a Computer for Playing Chess}\cite{Shannon1950}, and by 1997 the \textit{Deep Blue} computer defeated Garry Kasparov, the reigning world champion, in a six game chess match.\cite{Campbell2002} Compare that with some of the most advanced autonomous humanoid robots to date displaying dexterity only comparable with that of a toddler. The task of finding a collision free path, performed constantly without thought by a human, is an example of this paradigm. For a robot to plan its own paths, it relies on a set of Motion Planning Algorithms.

Motion Planning Algorithms refer to the set of algorithms that find possible sequences of valid \gls{configuration}s for a robot in a space. In more simple terms, they are algorithms that determine the movements a robot can make in a map, with the intent of eventually finding a path from one point to another.

\subsection{Key Concepts}
    \subsubsection{\Gls{workspace}}
    The \gls{workspace}, more loosely known as the \textbf{map}, is the space which the robot and obstacles occupy. Obviously, \textbf{obstacles} refer to anything with which the robot cannot intersect.
    
    \subsubsection{Configuration}
    A configuration describes the position, orientation, and pose of the robot. The complexity of a robot's configuration is therefore dependant on the dimension of the \gls{workspace}, the complexity of the robot itself, and in what level of detail the robot must be represented. For example:
    \begin{itemize}
        \item Most simply, a robot can be represented as a point; by the Cartesian coordinates $(x,y)$ in \gls{2D} space and $(x,y,z)$ in \gls{3D} space.
        \item More realistically, a robot such as a drone may be represented in \gls{3D} as a 3D rectangular prism; by an origin point $(x,y,z)$ and 3 Euler angles $(\alpha,\beta,\gamma)$ describing its orientation.
        \item In a more complex form, a fixed-base, $N$ \glsfirst{DOF} robot would require an $N$-dimensional configuration.
    \end{itemize}

    \input{chapters/chapter2/figures/configuration.tex}

    \subsubsection{Occupancy Grid Map}
    An \glsfirst{OGM} is a method of representing the obstacles present in a \gls{workspace}. Obstacles are often irregularly shaped and computing collisions with such obstacles is near impossible. Therefore, the \gls{workspace} is discretized into grids, with grids that contain any part of the obstacle marked as occupied, even if only a small part of the grid is occupied. An \gls{OGM} will more accurately represent a \gls{workspace} with a higher resolution, shown in Figure \ref{fig:OGM}.

    \input{chapters/chapter2/figures/ogm}

\subsection{Rapidly-exploring Random Tree}
    
    % INTRO
    \glsfirst{RRT} is an algorithm designed to efficiently build a tree of collision-free paths in a high-complexity environment. The algorithm grows the tree by randomly sampling points and connecting them to the nearest existing node in the tree. It is inherently biased to grow towards large unsearched areas of the workspace. RRT was developed by S. LaVelle\cite{LaValle1998} and J. Kuffner\cite{LaValle2001}. It is frequently used in autonomous robotic motion planning problems such as autonomous drones.

    % SCOPE OF ALGORITHM
    \subsubsection{Scope}
        \gls{RRT} takes an initial configuration, a goal point, and an \glsfirst{OGM} as its input. This \gls{OGM} may be built and updated using \textit{\gls{a priori}} knowledge, sensor data from the robot, and other inputs. The algorithm will output a tree of collision free paths toward the goal, as demonstrated in Figure \ref{fig:rrt_scope}. \textbf{It does not calculate the fastest path from that tree}; that can be accomplished using algorithms such as \Gls{dijkstra's algorithm}.

        \input{chapters/chapter2/figures/rrt_scope}

    % ALGORITHM
    \subsubsection{Algorithm}

        Put simply, \gls{RRT} finds a path from start to finish by randomly exploring a workspace.
        Put more technically, it builds a tree of possible \glspl{configuration} (also known as a graph), connected by edges, for a robot of some physical description. It does so by selecting random \glspl{configuration} and adding them to the graph. 
        From this graph, a path from the initial \gls{configuration} to some goal \gls{configuration} can be found, given a high enough number of iterations. As such, \gls{RRT} can be considered \gls{probabilistically complete}.
        The pseudo-code for \gls{RRT} can be seen in Algorithm \ref{algorithm:rrt}
        
        % RRT Algorithm
        \input{chapters/chapter2/algorithms/rrt_alg}

        % Explanation of Algorithm, referencing visual step by step figure
        Algorithm \ref{algorithm:rrt} can be visually represented in Figure \ref{fig:rrt-step-by-step}, with the example showing a \gls{2D} robot operating in a \gls{2D} workspace.

        % Step By Step RRT Figure
        \input{chapters/chapter2/figures/rrt-step-by-step}

        % COLLISION DETECTION

        Algorithm \ref{algorithm:rrt} shows how \gls{RRT} builds a graph of possible \gls{configuration}s connected by edges in a completely free \gls{configuration} space. However, in real-world applications, a robot's \gls{workspace} space will contain obstacles. As such, collision detection must be included in the algorithm. The two types of collisions the algorithm must check for are \textit{configuration collisions} (those where the robot would collide with an obstacle in a given \gls{configuration}) and \textit{edge collisions} (where the robot would collide when moving between two collision free \gls{configuration}s).

        \gls{RRT} with \gls{configuration} and edge collision detection can be seen in Algorithm \ref{algorithm:rrt_collision}. The method of implementing \gls{RRT} with collision detection to model a drone in 3D space is detailed in Section \ref{section:rrt}.

        \input{chapters/chapter2/algorithms/rrt_alg_collision}
